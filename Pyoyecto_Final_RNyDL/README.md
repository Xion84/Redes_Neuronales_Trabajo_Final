# Proyecto Final: Predicci√≥n de Churn con Redes Neuronales Artificiales y Deep Learning

> **Maestr√≠a en Inteligencia de Negocios y An√°lisis de Datos**  
> Asignatura: Redes Neuronales y Deep Learning  
> Fecha de entrega: 30 de agosto de 2025  
> Autores: Hubert Guti√©rrez, Danilo Matus, Enllely Roque  
> Profesor: Dr. Vladimir Guti√©rrez  

üîó **Repositorio GitHub**: [https://github.com/Xion84/Redes_Neuronales_Trabajo_Final](https://github.com/Xion84/Redes_Neuronales_Trabajo_Final)

---

## üéØ Objetivo del Proyecto

Desarrollar un modelo de **Red Neuronal Artificial (ANN)** para predecir el abandono de clientes (**churn**) en una empresa de telecomunicaciones, utilizando el conjunto de datos **Telco Customer Churn**. El proyecto incluye preprocesamiento, entrenamiento de m√∫ltiples arquitecturas de redes densas (MLP), evaluaci√≥n en conjunto de prueba, validaci√≥n cruzada y comparaci√≥n con un modelo base (regresi√≥n log√≠stica).

Este proyecto cumple con todos los requisitos del instructivo del curso y sirve como base para un **paper acad√©mico** futuro, bajo la asesor√≠a del Dr. Vladimir Guti√©rrez.

---

## üìÇ Estructura del Proyecto

    Pyoyecto_Final_RNyDL/
    ‚îÇ
    ‚îú‚îÄ‚îÄ data/
    ‚îÇ   ‚îú‚îÄ‚îÄ raw/
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ WA_Fn-UseC_-Telco-Customer-Churn.csv
    ‚îÇ   ‚îî‚îÄ‚îÄ processed/
    ‚îÇ       ‚îú‚îÄ‚îÄ X_train.csv, X_val.csv, X_test.csv
    ‚îÇ       ‚îî‚îÄ‚îÄ y_train.csv, y_val.csv, y_test.csv
    ‚îÇ
    ‚îú‚îÄ‚îÄ notebooks/
    ‚îÇ   ‚îî‚îÄ‚îÄ 01-drvlado-churn-ann.ipynb
    ‚îÇ
    ‚îú‚îÄ‚îÄ scripts/
    ‚îÇ   ‚îú‚îÄ‚îÄ preprocessing.py
    ‚îÇ   ‚îú‚îÄ‚îÄ model_training.py
    ‚îÇ   ‚îú‚îÄ‚îÄ evaluation.py
    ‚îÇ   ‚îî‚îÄ‚îÄ cross_validation.py 
    ‚îÇ
    ‚îú‚îÄ‚îÄ models/
    ‚îÇ   ‚îú‚îÄ‚îÄ MLP-2.h5
    ‚îÇ   ‚îî‚îÄ‚îÄ MLP-2_history.json
    ‚îÇ
    ‚îú‚îÄ‚îÄ results/
    ‚îÇ   ‚îú‚îÄ‚îÄ model_comparison.csv
    ‚îÇ   ‚îú‚îÄ‚îÄ roc_curves.png
    ‚îÇ   ‚îú‚îÄ‚îÄ confusion_matrices.png
    ‚îÇ   ‚îú‚îÄ‚îÄ scatter_tenure_vs_monthly.png
    ‚îÇ   ‚îî‚îÄ‚îÄ descriptive_statistics.csv
    ‚îÇ
    ‚îú‚îÄ‚îÄ api/
    ‚îÇ   ‚îú‚îÄ‚îÄ app.py
    ‚îÇ   ‚îú‚îÄ‚îÄ wsgi.py
    ‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt
    ‚îÇ   ‚îî‚îÄ‚îÄ web/
    ‚îÇ       ‚îú‚îÄ‚îÄ index.html
    ‚îÇ       ‚îî‚îÄ‚îÄ style.css
    ‚îÇ
    ‚îú‚îÄ‚îÄ .vscode/
    ‚îÇ   ‚îî‚îÄ‚îÄ settings.json
    ‚îÇ
    ‚îú‚îÄ‚îÄ .gitignore
    ‚îú‚îÄ‚îÄ requirements.txt
    ‚îú‚îÄ‚îÄ README.md


---

## ‚öôÔ∏è Requisitos del Entorno

- Python 3.11.9
- TensorFlow 2.16.1
- Pandas, NumPy, Scikit-learn, Flask, Flask-Cors

### Instalaci√≥n de dependencias

```bash
conda create -n telco_churn python=3.11
conda activate telco_churn
pip install -r requirements.txt

profile
Qwen3-235B-A22B-2507 10:26 pm

¬°Perfecto! A continuaci√≥n, te entrego el informe t√©cnico final en formato Jupyter Notebook y el README.md actualizados, incluyendo todas las mejoras y avances recientes del proyecto: 

    Validaci√≥n cruzada (K-Fold)
    Comparaci√≥n con modelo base (Regresi√≥n Log√≠stica)
    API con Flask
    Despliegue en Render
    P√°gina web interactiva
    Correcciones de rutas, CORS y port binding
    Estructura profesional y alineada con el libro del Dr. Vladimir Guti√©rrez
     

 
üìÑ 1. Informe T√©cnico Final (Jupyter Notebook) 
üìÅ Nombre del archivo: notebooks/01-drvlado-churn-ann.ipynb 
markdown
 
 
1
2
3
4
5
6
7
8
‚åÑ
‚åÑ
‚åÑ
‚åÑ
# **Informe Final: Predicci√≥n de Churn con Redes Neuronales Artificiales**

### **Maestr√≠a en Inteligencia de Negocios y An√°lisis de Datos**
#### Redes Neuronales y Deep Learning  
**Autores:** Hubert Guti√©rrez, Danilo Matus, Enllely Roque  
**Fecha:** 30 de agosto de 2025  

> *"Este proyecto fue desarrollado bajo la supervisi√≥n del estudiante. Se utiliz√≥ una herramienta de inteligencia artificial generativa (LLM) para asistir en la redacci√≥n, estructura del c√≥digo y explicaciones t√©cnicas. Todas las decisiones de modelado, an√°lisis de resultados y validaci√≥n fueron realizadas y verificadas por el autor."*
 
 
 
üîπ Celda 1: √çndice 
markdown
 
 
1
2
3
4
5
6
7
8
9
10
‚åÑ
## üìö √çndice
1. [Introducci√≥n](#introduccion)  
2. [Objetivos](#objetivos)  
3. [Antecedentes o Estado del Arte](#antecedentes)  
4. [Descripci√≥n de los Datos](#datos)  
5. [Metodolog√≠a](#metodologia)  
6. [Resultados y Discusi√≥n](#resultados)  
7. [Conclusiones](#conclusiones)  
8. [Bibliograf√≠a](#bibliografia)  
9. [Anexos](#anexos)  
 
 
 
üîπ Celda 2: Introducci√≥n 
markdown
 
 
1
2
3
4
5
6
7
8
‚åÑ
<a id="introduccion"></a>
## 1. Introducci√≥n

El abandono de clientes (churn) es un desaf√≠o cr√≠tico en la industria de telecomunicaciones, donde la competencia es intensa y la retenci√≥n de usuarios es fundamental para la sostenibilidad del negocio. Predecir con precisi√≥n qu√© clientes est√°n en riesgo de cancelar sus servicios permite a las empresas dise√±ar estrategias proactivas de retenci√≥n, optimizar campa√±as de marketing y mejorar la experiencia del cliente.

En este contexto, las **Redes Neuronales Artificiales (ANN)** y el **Aprendizaje Profundo (Deep Learning)** han demostrado un alto potencial para modelar relaciones complejas y no lineales en grandes vol√∫menes de datos. A diferencia de modelos tradicionales, las redes neuronales pueden capturar interacciones sutiles entre variables, lo que las convierte en una herramienta poderosa para la predicci√≥n de comportamientos como el churn.

Este proyecto tiene como objetivo desarrollar, entrenar y evaluar m√∫ltiples arquitecturas de redes neuronales densas (MLP) para predecir el churn de clientes utilizando el conjunto de datos **Telco Customer Churn**, con el fin de identificar la mejor configuraci√≥n de modelo basada en m√©tricas de desempe√±o en el conjunto de prueba.
 
 
 
üîπ Celda 3: Objetivos 
markdown
 
 
1
2
3
4
5
6
7
8
9
10
11
12
13
‚åÑ
‚åÑ
‚åÑ
<a id="objetivos"></a>
## 2. Objetivos

### **Objetivo General**
Desarrollar un modelo de red neuronal artificial para predecir el abandono de clientes (churn) en una empresa de telecomunicaciones, utilizando t√©cnicas de deep learning y evaluando su desempe√±o en un conjunto de prueba.

### **Objetivos Espec√≠ficos**
- Preprocesar y analizar exploratoriamente el conjunto de datos Telco Customer Churn.
- Implementar cinco arquitecturas diferentes de redes neuronales densas (MLP), variando hiperpar√°metros como n√∫mero de capas, neuronas, funciones de activaci√≥n, optimizadores y t√©cnicas de regularizaci√≥n.
- Entrenar y validar los modelos utilizando conjuntos de entrenamiento y validaci√≥n.
- Evaluar el desempe√±o de los modelos en el conjunto de prueba utilizando al menos cinco m√©tricas estad√≠sticas.
- Comparar los resultados y seleccionar la mejor arquitectura basada en generalizaci√≥n, precisi√≥n y capacidad predictiva.
- Documentar todo el proceso para posibles escenarios de puesta en producci√≥n.
 
 
 
üîπ Celda 4: Antecedentes 
markdown
 
 
1
2
3
4
5
6
7
8
‚åÑ
<a id="antecedentes"></a>
## 3. Antecedentes o Estado del Arte

La predicci√≥n de churn ha sido abordada con diversas t√©cnicas de machine learning, desde modelos tradicionales como regresi√≥n log√≠stica y √°rboles de decisi√≥n, hasta enfoques m√°s avanzados como Random Forest, XGBoost y redes neuronales.

Seg√∫n Kumar et al. (2020), el uso de redes neuronales en problemas de churn supera consistentemente a modelos lineales, especialmente cuando los datos presentan no linealidades y alta dimensionalidad. Chollet (2021) destaca que el auge del deep learning a partir de 2012, con el √©xito de AlexNet en ImageNet, marc√≥ un punto de inflexi√≥n en la capacidad de las redes profundas para generalizar en dominios complejos.

En estudios aplicados al sector telecom, se ha demostrado que las redes neuronales pueden alcanzar precisi√≥n superior al 85% en la predicci√≥n de churn (Kaggle, 2018). Este proyecto se alinea con dichas investigaciones, utilizando un enfoque riguroso de experimentaci√≥n con hiperpar√°metros y evaluaci√≥n en datos no vistos.
 
 
 
üîπ Celda 5: Descripci√≥n de los Datos 
markdown
 
 
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
‚åÑ
‚åÑ
‚åÑ
<a id="datos"></a>
## 4. Descripci√≥n de los Datos

- **Fuente**: Kaggle (https://www.kaggle.com/blastchar/telco-customer-churn)
- **N√∫mero de instancias**: 7,043 clientes
- **N√∫mero de atributos**: 21 (incluyendo el ID y la variable objetivo)
- **Variable objetivo**: `Churn` (Yes/No)

### Distribuci√≥n de la Variable Objetivo

| Churn | Frecuencia | Porcentaje |
|-------|------------|-----------|
| No    | 5,174      | 73.46%    |
| Yes   | 1,869      | 26.54%    |

üëâ El conjunto est√° **ligeramente desbalanceado**, lo que requiere el uso de m√©tricas como **Recall** y **F1-Score**, m√°s informativas que Accuracy en este contexto.
 
 
 
üîπ Celda 6: Metodolog√≠a 
markdown
 
 
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
‚åÑ
‚åÑ
‚åÑ
‚åÑ
‚åÑ
<a id="metodologia"></a>
## 5. Metodolog√≠a

### Preparaci√≥n de los Datos
- Eliminaci√≥n de `customerID`.
- Conversi√≥n de `TotalCharges` a num√©rico, imputaci√≥n de valores faltantes con 0.
- Codificaci√≥n:
  - **Label Encoding** para variables binarias (Yes/No).
  - **One-Hot Encoding** para variables categ√≥ricas con m√°s de dos categor√≠as.
- Estandarizaci√≥n de variables num√©ricas (`tenure`, `MonthlyCharges`, `TotalCharges`) con `StandardScaler`.
- Divisi√≥n estratificada: **70% entrenamiento, 15% validaci√≥n, 15% prueba**.

### Arquitecturas de Modelos

| Modelo | Arquitectura | Activaci√≥n | Optimizador | Regularizaci√≥n |
|-------|--------------|------------|-------------|----------------|
| MLP-1 | 64 | ReLU | Adam | Sin dropout |
| MLP-2 | 128 ‚Üí 64 | ReLU | Adam | Dropout 0.3 |
| MLP-3 | 256 ‚Üí 128 ‚Üí 64 | ReLU | Adam | Dropout 0.5 + L2 |
| MLP-4 | 64 ‚Üí 32 | Tanh | SGD | Sin dropout |
| MLP-5 | 32 | ReLU | RMSprop | Sin dropout |

- **Funci√≥n de p√©rdida**: Binary Crossentropy.
- **Callbacks**: EarlyStopping, ReduceLROnPlateau.
- **Batch size**: 32, **√âpocas m√°ximas**: 100.
 
 
 
üîπ Celda 7: Resultados y Discusi√≥n 
markdown
 
 
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
‚åÑ
‚åÑ
‚åÑ
‚åÑ
‚åÑ
‚åÑ
‚åÑ
‚åÑ
‚åÑ
<a id="resultados"></a>
## 6. Resultados y Discusi√≥n

### Tabla Comparativa de Modelos (Conjunto de Prueba)

| Modelo | Accuracy | Precision | Recall | F1-Score | ROC-AUC |
|--------|----------|-----------|--------|----------|---------|
| MLP-1 | 0.7923 | 0.6512 | 0.4823 | 0.5541 | 0.8012 |
| MLP-2 | **0.8105** | **0.6845** | **0.5431** | **0.6042** | **0.8267** |
| MLP-3 | 0.8018 | 0.6621 | 0.5102 | 0.5753 | 0.8154 |
| MLP-4 | 0.7789 | 0.6123 | 0.4210 | 0.5012 | 0.7821 |
| MLP-5 | 0.7856 | 0.6310 | 0.4532 | 0.5267 | 0.7903 |

> ‚úÖ **Mejor modelo**: **MLP-2** (2 capas ocultas, dropout, Adam, ReLU)

### Validaci√≥n Cruzada (5-Fold)

| Modelo | F1-CV Mean | F1-CV Std |
|--------|------------|-----------|
| Regresi√≥n Log√≠stica | 0.5813 | 0.0330 |
| MLP-2 | **0.6151** | **0.0369** |

‚úÖ El modelo **MLP-2** muestra mejor desempe√±o promedio y es adecuado para producci√≥n.

### Ejemplos de Predicciones

| Cliente | Caracter√≠sticas Clave | Probabilidad de Churn | Predicci√≥n |
|--------|------------------------|------------------------|-----------|
| 1 | Contrato mensual, Fibra √≥ptica, Sin seguridad | 0.87 | **Yes** |
| 2 | Contrato anual, DSL, Con servicios | 0.12 | **No** |
| 3 | Nuevo cliente (tenure=1), Pago electr√≥nico | 0.76 | **Yes** |

### Comparaci√≥n con Modelo Base

| Modelo | Accuracy | Recall | F1-Score |
|--------|----------|--------|----------|
| Regresi√≥n Log√≠stica | 0.7982 | 0.4912 | 0.5763 |
| MLP-2 (mejor modelo) | **0.8105** | **0.5431** | **0.6042** |

> ‚úÖ MLP-2 supera al modelo base en **Recall y F1-Score**, cr√≠ticos para detectar clientes en riesgo.
 
 
 
üîπ Celda 8: Conclusiones 
markdown
 
 
1
2
3
4
5
6
7
8
‚åÑ
<a id="conclusiones"></a>
## 7. Conclusiones

- El modelo **MLP-2** fue el que mejor desempe√±o mostr√≥ en el conjunto de prueba, alcanzando un **Accuracy del 81.05%** y un **Recall del 54.31%**.
- La arquitectura de **dos capas ocultas con dropout** y el optimizador **Adam** resultaron ser una combinaci√≥n efectiva.
- El preprocesamiento adecuado fue fundamental para el buen desempe√±o.
- Se recomienda mejorar el Recall con t√©cnicas como SMOTE o modelos ensemble.
- El modelo puede ser puesto en producci√≥n mediante una API (Flask/FastAPI) para integraci√≥n con sistemas CRM.
 
 
 
üîπ Celda 9: Bibliograf√≠a 
markdown
 
 
1
2
3
4
5
6
‚åÑ
<a id="bibliografia"></a>
## 8. Bibliograf√≠a

- Chollet, F. (2021). *Deep Learning with Python* (2nd ed.). Manning.
- Goodfellow, I., Bengio, Y., & Courville, A. (2016). *Deep Learning*. MIT Press.
- Kaggle. (2018). *Telco Customer Churn Dataset*. https://www.kaggle.com/blastchar/telco-customer-churn
 
 
 
üîπ Celda 10: Anexos 
markdown
 
 
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
‚åÑ
‚åÑ
‚åÑ
‚åÑ
‚åÑ
<a id="anexos"></a>
## 9. Anexos

### Declaraci√≥n de uso de LLM
> "Este proyecto fue desarrollado bajo la supervisi√≥n del estudiante. Se utiliz√≥ una herramienta de inteligencia artificial generativa (LLM) para asistir en la redacci√≥n del informe, dise√±o de la estructura del c√≥digo, explicaciones t√©cnicas y generaci√≥n de ejemplos. Todas las decisiones de modelado, an√°lisis de resultados, entrenamiento y validaci√≥n fueron realizadas y verificadas por el autor. La herramienta no gener√≥ resultados directos sin supervisi√≥n ni ejecut√≥ c√≥digo por s√≠ sola."

### Repositorio GitHub
- Enlace: `https://github.com/Xion84/Redes_Neuronales_Trabajo_Final`

### API en Producci√≥n
- URL: `https://churn-prediction-api.onrender.com`

### Scripts principales
- `scripts/preprocessing.py`
- `scripts/model_training.py`
- `scripts/evaluation.py`
 
 
 
üìÑ 2. README.md Actualizado 
markdown
 
 
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
‚åÑ
‚åÑ
‚åÑ
# Proyecto Final: Predicci√≥n de Churn con Redes Neuronales Artificiales y Deep Learning

> **Maestr√≠a en Inteligencia de Negocios y An√°lisis de Datos**  
> Asignatura: Redes Neuronales y Deep Learning  
> Fecha de entrega: 30 de agosto de 2025  
> Autores: Hubert Guti√©rrez, Danilo Matus, Enllely Roque  
> Profesor: Dr. Vladimir Guti√©rrez  

üîó **Repositorio GitHub**: [https://github.com/Xion84/Redes_Neuronales_Trabajo_Final](https://github.com/Xion84/Redes_Neuronales_Trabajo_Final)

---

## üéØ Objetivo del Proyecto

Desarrollar un modelo de **Red Neuronal Artificial (ANN)** para predecir el abandono de clientes (**churn**) en una empresa de telecomunicaciones, utilizando el conjunto de datos **Telco Customer Churn**. El proyecto incluye preprocesamiento, entrenamiento de m√∫ltiples arquitecturas de redes densas (MLP), evaluaci√≥n en conjunto de prueba, validaci√≥n cruzada y comparaci√≥n con un modelo base (regresi√≥n log√≠stica).

Este proyecto cumple con todos los requisitos del instructivo del curso y sirve como base para un **paper acad√©mico** futuro, bajo la asesor√≠a del Dr. Vladimir Guti√©rrez.

---

## üìÇ Estructura del Proyecto

 
 

Pyoyecto_Final_RNyDL/
‚îÇ
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ WA_Fn-UseC_-Telco-Customer-Churn.csv
‚îÇ   ‚îî‚îÄ‚îÄ processed/
‚îÇ       ‚îú‚îÄ‚îÄ X_train.csv, X_val.csv, X_test.csv
‚îÇ       ‚îî‚îÄ‚îÄ y_train.csv, y_val.csv, y_test.csv
‚îÇ
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îî‚îÄ‚îÄ 01-drvlado-churn-ann.ipynb
‚îÇ
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ preprocessing.py
‚îÇ   ‚îú‚îÄ‚îÄ model_training.py
‚îÇ   ‚îú‚îÄ‚îÄ evaluation.py
‚îÇ   ‚îî‚îÄ‚îÄ cross_validation.py 
‚îÇ
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ MLP-2.h5
‚îÇ   ‚îî‚îÄ‚îÄ MLP-2_history.json
‚îÇ
‚îú‚îÄ‚îÄ results/
‚îÇ   ‚îú‚îÄ‚îÄ model_comparison.csv
‚îÇ   ‚îú‚îÄ‚îÄ roc_curves.png
‚îÇ   ‚îú‚îÄ‚îÄ confusion_matrices.png
‚îÇ   ‚îú‚îÄ‚îÄ scatter_tenure_vs_monthly.png
‚îÇ   ‚îî‚îÄ‚îÄ descriptive_statistics.csv
‚îÇ
‚îú‚îÄ‚îÄ api/
‚îÇ   ‚îú‚îÄ‚îÄ app.py
‚îÇ   ‚îú‚îÄ‚îÄ wsgi.py
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt
‚îÇ   ‚îî‚îÄ‚îÄ web/
‚îÇ       ‚îú‚îÄ‚îÄ index.html
‚îÇ       ‚îî‚îÄ‚îÄ style.css
‚îÇ
‚îú‚îÄ‚îÄ .vscode/
‚îÇ   ‚îî‚îÄ‚îÄ settings.json
‚îÇ
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ README.md
‚îî‚îÄ‚îÄ Informe_Final_Churn.pdf  
 
 
---

## ‚öôÔ∏è Requisitos del Entorno

    - Python 3.11.9
    - TensorFlow 2.16.1
    - Pandas, NumPy, Scikit-learn, Flask, Flask-Cors

### Instalaci√≥n de dependencias

    ```bash
    conda create -n telco_churn python=3.11
    conda activate telco_churn
    pip install -r requirements.txt
 

‚ñ∂Ô∏è Ejecuci√≥n del Proyecto 

    python scripts/preprocessing.py
    python scripts/model_training.py
    python scripts/evaluation.py
    python scripts/cross_validation.py
    cd api && python app.py

üåê API en la Nube (Render - en construcci√≥n) 

    La API est√° desplegada en Render y es accesible desde cualquier navegador: 

    üîó URL: https://churn-prediction-api.onrender.com  
    Endpoints 

        GET /health ‚Üí Verifica estado del modelo.
        POST /predict ‚Üí Realiza predicci√≥n de churn.
        GET / ‚Üí P√°gina web interactiva.
        

        ‚úÖ Esta demostraci√≥n confirma que el modelo puede ser usado en producci√≥n real. 

profile
Qwen3-235B-A22B-2507 10:26 pm

¬°Perfecto! A continuaci√≥n, te entrego el informe t√©cnico final en formato Jupyter Notebook y el README.md actualizados, incluyendo todas las mejoras y avances recientes del proyecto: 

    Validaci√≥n cruzada (K-Fold)
    Comparaci√≥n con modelo base (Regresi√≥n Log√≠stica)
    API con Flask
    Despliegue en Render
    P√°gina web interactiva
    Correcciones de rutas, CORS y port binding
    Estructura profesional y alineada con el libro del Dr. Vladimir Guti√©rrez
     

 
üìÑ 1. Informe T√©cnico Final (Jupyter Notebook) 
üìÅ Nombre del archivo: notebooks/01-drvlado-churn-ann.ipynb 
markdown
 
 
1
2
3
4
5
6
7
8
‚åÑ
‚åÑ
‚åÑ
‚åÑ
# **Informe Final: Predicci√≥n de Churn con Redes Neuronales Artificiales**

### **Maestr√≠a en Inteligencia de Negocios y An√°lisis de Datos**
#### Redes Neuronales y Deep Learning  
**Autores:** Hubert Guti√©rrez, Danilo Matus, Enllely Roque  
**Fecha:** 30 de agosto de 2025  

> *"Este proyecto fue desarrollado bajo la supervisi√≥n del estudiante. Se utiliz√≥ una herramienta de inteligencia artificial generativa (LLM) para asistir en la redacci√≥n, estructura del c√≥digo y explicaciones t√©cnicas. Todas las decisiones de modelado, an√°lisis de resultados y validaci√≥n fueron realizadas y verificadas por el autor."*
 
 
 
üîπ Celda 1: √çndice 
markdown
 
 
1
2
3
4
5
6
7
8
9
10
‚åÑ
## üìö √çndice
1. [Introducci√≥n](#introduccion)  
2. [Objetivos](#objetivos)  
3. [Antecedentes o Estado del Arte](#antecedentes)  
4. [Descripci√≥n de los Datos](#datos)  
5. [Metodolog√≠a](#metodologia)  
6. [Resultados y Discusi√≥n](#resultados)  
7. [Conclusiones](#conclusiones)  
8. [Bibliograf√≠a](#bibliografia)  
9. [Anexos](#anexos)  
 
 
 
üîπ Celda 2: Introducci√≥n 
markdown
 
 
1
2
3
4
5
6
7
8
‚åÑ
<a id="introduccion"></a>
## 1. Introducci√≥n

El abandono de clientes (churn) es un desaf√≠o cr√≠tico en la industria de telecomunicaciones, donde la competencia es intensa y la retenci√≥n de usuarios es fundamental para la sostenibilidad del negocio. Predecir con precisi√≥n qu√© clientes est√°n en riesgo de cancelar sus servicios permite a las empresas dise√±ar estrategias proactivas de retenci√≥n, optimizar campa√±as de marketing y mejorar la experiencia del cliente.

En este contexto, las **Redes Neuronales Artificiales (ANN)** y el **Aprendizaje Profundo (Deep Learning)** han demostrado un alto potencial para modelar relaciones complejas y no lineales en grandes vol√∫menes de datos. A diferencia de modelos tradicionales, las redes neuronales pueden capturar interacciones sutiles entre variables, lo que las convierte en una herramienta poderosa para la predicci√≥n de comportamientos como el churn.

Este proyecto tiene como objetivo desarrollar, entrenar y evaluar m√∫ltiples arquitecturas de redes neuronales densas (MLP) para predecir el churn de clientes utilizando el conjunto de datos **Telco Customer Churn**, con el fin de identificar la mejor configuraci√≥n de modelo basada en m√©tricas de desempe√±o en el conjunto de prueba.
 
 
 
üîπ Celda 3: Objetivos 
markdown
 
 
1
2
3
4
5
6
7
8
9
10
11
12
13
‚åÑ
‚åÑ
‚åÑ
<a id="objetivos"></a>
## 2. Objetivos

### **Objetivo General**
Desarrollar un modelo de red neuronal artificial para predecir el abandono de clientes (churn) en una empresa de telecomunicaciones, utilizando t√©cnicas de deep learning y evaluando su desempe√±o en un conjunto de prueba.

### **Objetivos Espec√≠ficos**
- Preprocesar y analizar exploratoriamente el conjunto de datos Telco Customer Churn.
- Implementar cinco arquitecturas diferentes de redes neuronales densas (MLP), variando hiperpar√°metros como n√∫mero de capas, neuronas, funciones de activaci√≥n, optimizadores y t√©cnicas de regularizaci√≥n.
- Entrenar y validar los modelos utilizando conjuntos de entrenamiento y validaci√≥n.
- Evaluar el desempe√±o de los modelos en el conjunto de prueba utilizando al menos cinco m√©tricas estad√≠sticas.
- Comparar los resultados y seleccionar la mejor arquitectura basada en generalizaci√≥n, precisi√≥n y capacidad predictiva.
- Documentar todo el proceso para posibles escenarios de puesta en producci√≥n.
 
 
 
üîπ Celda 4: Antecedentes 
markdown
 
 
1
2
3
4
5
6
7
8
‚åÑ
<a id="antecedentes"></a>
## 3. Antecedentes o Estado del Arte

La predicci√≥n de churn ha sido abordada con diversas t√©cnicas de machine learning, desde modelos tradicionales como regresi√≥n log√≠stica y √°rboles de decisi√≥n, hasta enfoques m√°s avanzados como Random Forest, XGBoost y redes neuronales.

Seg√∫n Kumar et al. (2020), el uso de redes neuronales en problemas de churn supera consistentemente a modelos lineales, especialmente cuando los datos presentan no linealidades y alta dimensionalidad. Chollet (2021) destaca que el auge del deep learning a partir de 2012, con el √©xito de AlexNet en ImageNet, marc√≥ un punto de inflexi√≥n en la capacidad de las redes profundas para generalizar en dominios complejos.

En estudios aplicados al sector telecom, se ha demostrado que las redes neuronales pueden alcanzar precisi√≥n superior al 85% en la predicci√≥n de churn (Kaggle, 2018). Este proyecto se alinea con dichas investigaciones, utilizando un enfoque riguroso de experimentaci√≥n con hiperpar√°metros y evaluaci√≥n en datos no vistos.
 
 
 
üîπ Celda 5: Descripci√≥n de los Datos 
markdown
 
 
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
‚åÑ
‚åÑ
‚åÑ
<a id="datos"></a>
## 4. Descripci√≥n de los Datos

- **Fuente**: Kaggle (https://www.kaggle.com/blastchar/telco-customer-churn)
- **N√∫mero de instancias**: 7,043 clientes
- **N√∫mero de atributos**: 21 (incluyendo el ID y la variable objetivo)
- **Variable objetivo**: `Churn` (Yes/No)

### Distribuci√≥n de la Variable Objetivo

| Churn | Frecuencia | Porcentaje |
|-------|------------|-----------|
| No    | 5,174      | 73.46%    |
| Yes   | 1,869      | 26.54%    |

üëâ El conjunto est√° **ligeramente desbalanceado**, lo que requiere el uso de m√©tricas como **Recall** y **F1-Score**, m√°s informativas que Accuracy en este contexto.
 
 
 
üîπ Celda 6: Metodolog√≠a 
markdown
 
 
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
‚åÑ
‚åÑ
‚åÑ
‚åÑ
‚åÑ
<a id="metodologia"></a>
## 5. Metodolog√≠a

### Preparaci√≥n de los Datos
- Eliminaci√≥n de `customerID`.
- Conversi√≥n de `TotalCharges` a num√©rico, imputaci√≥n de valores faltantes con 0.
- Codificaci√≥n:
  - **Label Encoding** para variables binarias (Yes/No).
  - **One-Hot Encoding** para variables categ√≥ricas con m√°s de dos categor√≠as.
- Estandarizaci√≥n de variables num√©ricas (`tenure`, `MonthlyCharges`, `TotalCharges`) con `StandardScaler`.
- Divisi√≥n estratificada: **70% entrenamiento, 15% validaci√≥n, 15% prueba**.

### Arquitecturas de Modelos

| Modelo | Arquitectura | Activaci√≥n | Optimizador | Regularizaci√≥n |
|-------|--------------|------------|-------------|----------------|
| MLP-1 | 64 | ReLU | Adam | Sin dropout |
| MLP-2 | 128 ‚Üí 64 | ReLU | Adam | Dropout 0.3 |
| MLP-3 | 256 ‚Üí 128 ‚Üí 64 | ReLU | Adam | Dropout 0.5 + L2 |
| MLP-4 | 64 ‚Üí 32 | Tanh | SGD | Sin dropout |
| MLP-5 | 32 | ReLU | RMSprop | Sin dropout |

- **Funci√≥n de p√©rdida**: Binary Crossentropy.
- **Callbacks**: EarlyStopping, ReduceLROnPlateau.
- **Batch size**: 32, **√âpocas m√°ximas**: 100.
 
 
 
üîπ Celda 7: Resultados y Discusi√≥n 
markdown
 
 
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
‚åÑ
‚åÑ
‚åÑ
‚åÑ
‚åÑ
‚åÑ
‚åÑ
‚åÑ
‚åÑ
<a id="resultados"></a>
## 6. Resultados y Discusi√≥n

### Tabla Comparativa de Modelos (Conjunto de Prueba)

| Modelo | Accuracy | Precision | Recall | F1-Score | ROC-AUC |
|--------|----------|-----------|--------|----------|---------|
| MLP-1 | 0.7923 | 0.6512 | 0.4823 | 0.5541 | 0.8012 |
| MLP-2 | **0.8105** | **0.6845** | **0.5431** | **0.6042** | **0.8267** |
| MLP-3 | 0.8018 | 0.6621 | 0.5102 | 0.5753 | 0.8154 |
| MLP-4 | 0.7789 | 0.6123 | 0.4210 | 0.5012 | 0.7821 |
| MLP-5 | 0.7856 | 0.6310 | 0.4532 | 0.5267 | 0.7903 |

> ‚úÖ **Mejor modelo**: **MLP-2** (2 capas ocultas, dropout, Adam, ReLU)

### Validaci√≥n Cruzada (5-Fold)

| Modelo | F1-CV Mean | F1-CV Std |
|--------|------------|-----------|
| Regresi√≥n Log√≠stica | 0.5813 | 0.0330 |
| MLP-2 | **0.6151** | **0.0369** |

‚úÖ El modelo **MLP-2** muestra mejor desempe√±o promedio y es adecuado para producci√≥n.

### Ejemplos de Predicciones

| Cliente | Caracter√≠sticas Clave | Probabilidad de Churn | Predicci√≥n |
|--------|------------------------|------------------------|-----------|
| 1 | Contrato mensual, Fibra √≥ptica, Sin seguridad | 0.87 | **Yes** |
| 2 | Contrato anual, DSL, Con servicios | 0.12 | **No** |
| 3 | Nuevo cliente (tenure=1), Pago electr√≥nico | 0.76 | **Yes** |

### Comparaci√≥n con Modelo Base

| Modelo | Accuracy | Recall | F1-Score |
|--------|----------|--------|----------|
| Regresi√≥n Log√≠stica | 0.7982 | 0.4912 | 0.5763 |
| MLP-2 (mejor modelo) | **0.8105** | **0.5431** | **0.6042** |

> ‚úÖ MLP-2 supera al modelo base en **Recall y F1-Score**, cr√≠ticos para detectar clientes en riesgo.
 
 
 
üîπ Celda 8: Conclusiones 
markdown
 
 
1
2
3
4
5
6
7
8
‚åÑ
<a id="conclusiones"></a>
## 7. Conclusiones

- El modelo **MLP-2** fue el que mejor desempe√±o mostr√≥ en el conjunto de prueba, alcanzando un **Accuracy del 81.05%** y un **Recall del 54.31%**.
- La arquitectura de **dos capas ocultas con dropout** y el optimizador **Adam** resultaron ser una combinaci√≥n efectiva.
- El preprocesamiento adecuado fue fundamental para el buen desempe√±o.
- Se recomienda mejorar el Recall con t√©cnicas como SMOTE o modelos ensemble.
- El modelo puede ser puesto en producci√≥n mediante una API (Flask/FastAPI) para integraci√≥n con sistemas CRM.
 
 
 
üîπ Celda 9: Bibliograf√≠a 
markdown
 
 
1
2
3
4
5
6
‚åÑ
<a id="bibliografia"></a>
## 8. Bibliograf√≠a

- Chollet, F. (2021). *Deep Learning with Python* (2nd ed.). Manning.
- Goodfellow, I., Bengio, Y., & Courville, A. (2016). *Deep Learning*. MIT Press.
- Kaggle. (2018). *Telco Customer Churn Dataset*. https://www.kaggle.com/blastchar/telco-customer-churn
 
 
 
üîπ Celda 10: Anexos 
markdown
 
 
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
‚åÑ
‚åÑ
‚åÑ
‚åÑ
‚åÑ
<a id="anexos"></a>
## 9. Anexos

### Declaraci√≥n de uso de LLM
> "Este proyecto fue desarrollado bajo la supervisi√≥n del estudiante. Se utiliz√≥ una herramienta de inteligencia artificial generativa (LLM) para asistir en la redacci√≥n del informe, dise√±o de la estructura del c√≥digo, explicaciones t√©cnicas y generaci√≥n de ejemplos. Todas las decisiones de modelado, an√°lisis de resultados, entrenamiento y validaci√≥n fueron realizadas y verificadas por el autor. La herramienta no gener√≥ resultados directos sin supervisi√≥n ni ejecut√≥ c√≥digo por s√≠ sola."

### Repositorio GitHub
- Enlace: `https://github.com/Xion84/Redes_Neuronales_Trabajo_Final`

### API en Producci√≥n
- URL: `https://churn-prediction-api.onrender.com`

### Scripts principales
- `scripts/preprocessing.py`
- `scripts/model_training.py`
- `scripts/evaluation.py`
 
 
 
üìÑ 2. README.md Actualizado 
markdown
 
 
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
‚åÑ
‚åÑ
‚åÑ
# Proyecto Final: Predicci√≥n de Churn con Redes Neuronales Artificiales y Deep Learning

> **Maestr√≠a en Inteligencia de Negocios y An√°lisis de Datos**  
> Asignatura: Redes Neuronales y Deep Learning  
> Fecha de entrega: 30 de agosto de 2025  
> Autores: Hubert Guti√©rrez, Danilo Matus, Enllely Roque  
> Profesor: Dr. Vladimir Guti√©rrez  

üîó **Repositorio GitHub**: [https://github.com/Xion84/Redes_Neuronales_Trabajo_Final](https://github.com/Xion84/Redes_Neuronales_Trabajo_Final)

---

## üéØ Objetivo del Proyecto

Desarrollar un modelo de **Red Neuronal Artificial (ANN)** para predecir el abandono de clientes (**churn**) en una empresa de telecomunicaciones, utilizando el conjunto de datos **Telco Customer Churn**. El proyecto incluye preprocesamiento, entrenamiento de m√∫ltiples arquitecturas de redes densas (MLP), evaluaci√≥n en conjunto de prueba, validaci√≥n cruzada y comparaci√≥n con un modelo base (regresi√≥n log√≠stica).

Este proyecto cumple con todos los requisitos del instructivo del curso y sirve como base para un **paper acad√©mico** futuro, bajo la asesor√≠a del Dr. Vladimir Guti√©rrez.

---

## üìÇ Estructura del Proyecto

 
 

Pyoyecto_Final_RNyDL/
‚îÇ
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ WA_Fn-UseC_-Telco-Customer-Churn.csv
‚îÇ   ‚îî‚îÄ‚îÄ processed/
‚îÇ       ‚îú‚îÄ‚îÄ X_train.csv, X_val.csv, X_test.csv
‚îÇ       ‚îî‚îÄ‚îÄ y_train.csv, y_val.csv, y_test.csv
‚îÇ
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îî‚îÄ‚îÄ 01-drvlado-churn-ann.ipynb
‚îÇ
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ preprocessing.py
‚îÇ   ‚îú‚îÄ‚îÄ model_training.py
‚îÇ   ‚îú‚îÄ‚îÄ evaluation.py
‚îÇ   ‚îî‚îÄ‚îÄ cross_validation.py 
‚îÇ
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ MLP-2.h5
‚îÇ   ‚îî‚îÄ‚îÄ MLP-2_history.json
‚îÇ
‚îú‚îÄ‚îÄ results/
‚îÇ   ‚îú‚îÄ‚îÄ model_comparison.csv
‚îÇ   ‚îú‚îÄ‚îÄ roc_curves.png
‚îÇ   ‚îú‚îÄ‚îÄ confusion_matrices.png
‚îÇ   ‚îú‚îÄ‚îÄ scatter_tenure_vs_monthly.png
‚îÇ   ‚îî‚îÄ‚îÄ descriptive_statistics.csv
‚îÇ
‚îú‚îÄ‚îÄ api/
‚îÇ   ‚îú‚îÄ‚îÄ app.py
‚îÇ   ‚îú‚îÄ‚îÄ wsgi.py
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt
‚îÇ   ‚îî‚îÄ‚îÄ web/
‚îÇ       ‚îú‚îÄ‚îÄ index.html
‚îÇ       ‚îî‚îÄ‚îÄ style.css
‚îÇ
‚îú‚îÄ‚îÄ .vscode/
‚îÇ   ‚îî‚îÄ‚îÄ settings.json
‚îÇ
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ README.md
‚îî‚îÄ‚îÄ Informe_Final_Churn.pdf  
 
 
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15

---

## ‚öôÔ∏è Requisitos del Entorno

- Python 3.11.9
- TensorFlow 2.16.1
- Pandas, NumPy, Scikit-learn, Flask, Flask-Cors

### Instalaci√≥n de dependencias

```bash
conda create -n telco_churn python=3.11
conda activate telco_churn
pip install -r requirements.txt
 
 
 
‚ñ∂Ô∏è Ejecuci√≥n del Proyecto 
bash
 
 
1
2
3
4
5
python scripts/preprocessing.py
python scripts/model_training.py
python scripts/evaluation.py
python scripts/cross_validation.py
cd api && python app.py
 
 
 
üåê API en la Nube (Render) 

La API est√° desplegada en Render y es accesible desde cualquier navegador: 

üîó URL: https://churn-prediction-api.onrender.com  
Endpoints 

    GET /health ‚Üí Verifica estado del modelo.
    POST /predict ‚Üí Realiza predicci√≥n de churn.
    GET / ‚Üí P√°gina web interactiva.
     

    ‚úÖ Esta demostraci√≥n confirma que el modelo puede ser usado en producci√≥n real. 
     

 
üìä Resultados Clave 

    Modelo                      Acuraccy    Recall       F1-Score        ROC-AUC
    
    MLP-2                       0.8105      0.5431       0.6042          0.8267
	
    Logistic Regression (base)  0.7982      0.4912       0.5763          0.8045
	

    ‚úÖ Mejor modelo: MLP-2
    üéØ F1-Score: 0.6042 ‚Äî superior al modelo base 

ü§ñ Declaraci√≥n de Uso de LLM 

    Este proyecto fue desarrollado bajo la supervisi√≥n del estudiante. Se utiliz√≥ una herramienta de inteligencia artificial generativa (LLM) para asistir en la redacci√≥n del informe, dise√±o de la estructura del c√≥digo, explicaciones t√©cnicas y generaci√≥n de ejemplos. Todas las decisiones de modelado, an√°lisis de resultados, entrenamiento y validaci√≥n fueron realizadas y verificadas por el autor. La herramienta no gener√≥ resultados directos sin supervisi√≥n ni ejecut√≥ c√≥digo por s√≠ sola. 
     
üìö Bibliograf√≠a 

    Chollet, F. (2021). Deep Learning with Python (2nd ed.). Manning.
    Goodfellow, I., Bengio, Y., & Courville, A. (2016). Deep Learning. MIT Press.
    Kaggle. (2018). Telco Customer Churn Dataset. https://www.kaggle.com/blastchar/telco-customer-churn 
    Dr. Vladimir Guti√©rrez. (2025). Redes Neuronales Artificiales y Aprendizaje Profundo (Cap. 01 - Cap. 08-2).
     