# Proyecto Final: PredicciÃ³n de Churn con Redes Neuronales Artificiales y Deep Learning

> **MaestrÃ­a en AnÃ¡lisis de Datos e Inteligencia de Negocios**  
> Asignatura: Redes Neuronales y Deep Learning  
> Fecha de entrega: 16 de agosto de 2025  
> Autores: [Hubert GutiÃ©rrez, Danilo Matus, Enllely Roque]  
> Profesor: Dr. Vladimir GutiÃ©rrez  

---

## ğŸ¯ Objetivo del Proyecto

    Desarrollar un modelo de **Red Neuronal Artificial (ANN)** para predecir el abandono de clientes (**churn**) en una empresa de telecomunicaciones, utilizando el conjunto de datos **Telco Customer Churn**. El proyecto incluye preprocesamiento, entrenamiento de mÃºltiples arquitecturas de redes densas (MLP), evaluaciÃ³n en conjunto de prueba y comparaciÃ³n con un modelo base (regresiÃ³n logÃ­stica).

    Este proyecto cumple con todos los requisitos del instructivo del curso y sirve como base para un **paper acadÃ©mico** futuro, bajo la asesorÃ­a del Dr. Vladimir GutiÃ©rrez.

---

## ğŸ“‚ Estructura del Proyecto

    Pyoyecto_Final_RNyDL/
    â”‚
    â”œâ”€â”€ data/
    â”‚   â”œâ”€â”€ raw/
    â”‚   â”‚   â””â”€â”€ WA_Fn-UseC_-Telco-Customer-Churn.csv
    â”‚   â””â”€â”€ processed/
    â”‚       â”œâ”€â”€ X_train.csv, X_val.csv, X_test.csv
    â”‚       â””â”€â”€ y_train.csv, y_val.csv, y_test.csv
    â”‚
    â”œâ”€â”€ notebooks/
    â”‚   â””â”€â”€ 01-drvlado-churn-ann.ipynb
    â”‚
    â”œâ”€â”€ scripts/
    â”‚   â”œâ”€â”€ preprocessing.py
    â”‚   â”œâ”€â”€ model_training.py
    â”‚   â””â”€â”€ evaluation.py
    â”‚
    â”œâ”€â”€ models/
    â”‚   â”œâ”€â”€ MLP-1.h5, MLP-2.h5, ...
    â”‚   â””â”€â”€ MLP-1_history.json, ...
    â”‚
    â”œâ”€â”€ results/
    â”‚   â”œâ”€â”€ model_comparison.csv
    â”‚   â”œâ”€â”€ roc_curves.png
    â”‚   â”œâ”€â”€ confusion_matrices.png
    â”‚   â”œâ”€â”€ scatter_tenure_vs_monthly.png
    â”‚   â””â”€â”€ descriptive_statistics.csv
    â”‚
    â”œâ”€â”€ .vscode/
    â”‚   â””â”€â”€ settings.json
    â”‚
    â”œâ”€â”€ .gitignore
    â”œâ”€â”€ requirements.txt
    â”œâ”€â”€ README.md
 

## âš™ï¸ Requisitos
    1 - Python 3.10
    2 - TensorFlow 2.13
    3 - Pandas, NumPy, Scikit-learn

    4- Instala dependencias:
    ```bash
    pip install -r requirements.txt

    python main.py
    
â–¶ï¸ EjecuciÃ³n del Proyecto 

    Este proyecto sigue la metodologÃ­a Top-Down y baby steps enseÃ±ada por el Dr. GutiÃ©rrez, con celdas #%% en VS Code para desarrollo interactivo. 

    1. Preprocesamiento de datos:
    python scripts/preprocessing.py

    2. Entrenamiento de modelos:
    python scripts/model_training.py

    3. EvaluaciÃ³n de modelos:
    python scripts/evaluation.py
    
    "Todos los resultados se guardan automÃ¡ticamente en las carpetas models/ y results/."

--- 
 
 
ğŸ“Š Resultados 
    
   
    âœ… Mejor modelo: MLP-2 (2 capas ocultas, dropout 0.3, Adam, ReLU)

    ğŸ¯ F1-Score: 0.6042 â€” superior al modelo base

ğŸ§  MetodologÃ­a Aplicada 

    Top-Down + Baby Steps: DiseÃ±o incremental desde el main.py hasta la implementaciÃ³n de mÃ³dulos.
    VS Code como IDE principal, con celdas #%% para ejecuciÃ³n interactiva.
    Control de versiones con Git/GitHub, usando ramas main y development.
    Preprocesamiento: One-Hot Encoding, StandardScaler, divisiÃ³n estratificada 70/15/15.
    Modelos: 5 arquitecturas de MLP con variaciÃ³n de hiperparÃ¡metros.
    EvaluaciÃ³n: MÃ©tricas en conjunto de prueba (al menos 5 estadÃ­sticos).
    ComparaciÃ³n con modelo base: RegresiÃ³n LogÃ­stica.
     

ğŸ¤– DeclaraciÃ³n de Uso de LLM 

    Este proyecto fue desarrollado bajo la supervisiÃ³n del estudiante. Se utilizÃ³ una herramienta de inteligencia artificial generativa (LLM) para asistir en la redacciÃ³n del informe, diseÃ±o de la estructura del cÃ³digo, explicaciones tÃ©cnicas y generaciÃ³n de ejemplos. Todas las decisiones de modelado, anÃ¡lisis de resultados, entrenamiento y validaciÃ³n fueron realizadas y verificadas por el autor. La herramienta no generÃ³ resultados directos sin supervisiÃ³n ni ejecutÃ³ cÃ³digo por sÃ­ sola. 
     
ğŸ“š BibliografÃ­a 

    Chollet, F. (2021). Deep Learning with Python (2nd ed.). Manning.
    Goodfellow, I., Bengio, Y., & Courville, A. (2016). Deep Learning. MIT Press.
    Kaggle. (2018). Telco Customer Churn Dataset. https://www.kaggle.com/blastchar/telco-customer-churn 
    Dr. Vladimir GutiÃ©rrez. (2025). Redes Neuronales Artificiales y Aprendizaje Profundo (Cap. 01 - Cap. 08-2).
     
