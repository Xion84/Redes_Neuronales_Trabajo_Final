# Proyecto Final: PredicciÃ³n de Churn con Redes Neuronales Artificiales y Deep Learning

> **MaestrÃ­a en Inteligencia de Negocios y AnÃ¡lisis de Datos**  
> Asignatura: Redes Neuronales y Deep Learning  
> Fecha de entrega: 16 de agosto de 2025  
> Autores: Hubert GutiÃ©rrez, Danilo Matus, Enllely Roque  
> Profesor: Dr. Vladimir GutiÃ©rrez  

ğŸ”— **Repositorio GitHub**: [https://github.com/Xion84/Redes_Neuronales_Trabajo_Final](https://github.com/Xion84/Redes_Neuronales_Trabajo_Final)

---

## ğŸ¯ Objetivo del Proyecto

Desarrollar un modelo de **Red Neuronal Artificial (ANN)** para predecir el abandono de clientes (**churn**) en una empresa de telecomunicaciones, utilizando el conjunto de datos **Telco Customer Churn**. El proyecto incluye:

- Preprocesamiento de datos.
- Entrenamiento de mÃºltiples arquitecturas de redes densas (MLP).
- EvaluaciÃ³n en conjunto de prueba.
- ValidaciÃ³n cruzada (K-Fold).
- ComparaciÃ³n con modelo base (RegresiÃ³n LogÃ­stica).
- Puesta en producciÃ³n simulada mediante una API.

Este proyecto cumple con todos los requisitos del instructivo del curso y sirve como base para un **paper acadÃ©mico** futuro, bajo la asesorÃ­a del Dr. Vladimir GutiÃ©rrez.

---

## ğŸ“‚ Estructura del Proyecto

    Pyoyecto_Final_RNyDL/
    â”‚
    â”œâ”€â”€ data/
    â”‚   â”œâ”€â”€ raw/
    â”‚   â”‚   â””â”€â”€ WA_Fn-UseC_-Telco-Customer-Churn.csv
    â”‚   â””â”€â”€ processed/
    â”‚       â”œâ”€â”€ X_train.csv, X_val.csv, X_test.csv
    â”‚       â””â”€â”€ y_train.csv, y_val.csv, y_test.csv
    â”‚
    â”œâ”€â”€ notebooks/
    â”‚   â””â”€â”€ 01-drvlado-churn-ann.ipynb
    â”‚
    â”œâ”€â”€ scripts/
    â”‚   â”œâ”€â”€ preprocessing.py
    â”‚   â”œâ”€â”€ model_training.py
    â”‚   â”œâ”€â”€ evaluation.py
    â”‚   â””â”€â”€ cross_validation.py 
    â”‚
    â”œâ”€â”€ models/
    â”‚   â”œâ”€â”€ MLP-1.h5, MLP-2.h5, ...
    â”‚   â””â”€â”€ MLP-1_history.json, ...
    â”‚
    â”œâ”€â”€ results/
    â”‚   â”œâ”€â”€ model_comparison.csv
    â”‚   â”œâ”€â”€ roc_curves.png
    â”‚   â”œâ”€â”€ confusion_matrices.png
    â”‚   â”œâ”€â”€ scatter_tenure_vs_monthly.png
    â”‚   â”œâ”€â”€ descriptive_statistics.csv
    â”‚   â”œâ”€â”€ cv_comparison_boxplot.png
    â”‚   â””â”€â”€ cross_validation_results.csv
    â”‚
    â”œâ”€â”€ api/
    â”‚   â”œâ”€â”€ app.py
    â”‚   â”œâ”€â”€ wsgi.py
    â”‚   â”œâ”€â”€ requirements.txt
    â”‚   â””â”€â”€ web/
    â”‚       â”œâ”€â”€ index.html
    â”‚       â””â”€â”€ style.css
    â”‚
    â”œâ”€â”€ .vscode/
    â”‚   â””â”€â”€ settings.json
    â”‚
    â”œâ”€â”€ .gitignore
    â”œâ”€â”€ requirements.txt
    â”œâ”€â”€ README.md



---

## âš™ï¸ Requisitos del Entorno

  - Python 3.11.9
  - TensorFlow 2.16.1
  - Pandas, NumPy, Scikit-learn, Flask, Flask-Cors

### InstalaciÃ³n de dependencias

    ```bash
    # Crear entorno (recomendado con Conda)
    conda create -n telco_churn python=3.11
    conda activate telco_churn

    # Instalar dependencias
    pip install -r requirements.txt

â–¶ï¸ EjecuciÃ³n del Proyecto 

    Este proyecto sigue la metodologÃ­a Top-Down + Baby Steps enseÃ±ada por el Dr. GutiÃ©rrez, con celdas #%% en VS Code para desarrollo interactivo. 
    1. Preprocesamiento de datos 
    python scripts/preprocessing.py
    2. Entrenamiento de modelos
    python scripts/model_training.py
    3. EvaluaciÃ³n de modelos
    python scripts/evaluation.py
    4. ValidaciÃ³n cruzada
    python scripts/cross_validation.py

Resultados claves 

    Modelo                          Accuracy        Recall          F1-Score        ROC-AUC
    MLP-1                           0.7923          0.4823          0.5541          0.8012
    MLP-2                          	0.8105          0.5431 	        0.6042          0.8267
    MLP-3                           0.8018          0.5102          0.5753          0.8154
    MLP-4                           0.7789          0.4210          0.5012          0.7821
    MLP-5                           0.7856          0.4532          0.5267          0.7903
    Logistic Regression (base)      0.7982          0.4912          0.5763          0.8045

    âœ… Mejor modelo: MLP-2 (2 capas ocultas, dropout 0.3, Adam, ReLU)
    ğŸ¯ F1-Score: 0.6042 â€” superior al modelo base

ValidaciÃ³n Cruzada (5-Fold)

    Modelo                          F1-CV MEAN          F1-CV STD
    RegresiÃ³n LogÃ­stica             0.5813              0.0330
    MLP-2                           0.6151              0.0369

ğŸŒ API de ProducciÃ³n (Simulada) 

Una API simple con Flask permite exponer el modelo MLP-2 para predicciones en entornos de producciÃ³n. 
    Ejecutar la API 

    cd api
    python app.py

    Endpoint
    * POST /predict â†’ Recibe datos del cliente y devuelve probabilidad de churn.

    Ejemplo de solicitud (usando curl)

    curl -X POST http://localhost:5000/predict \
    -H "Content-Type: application/json" \
    -d '{
        "gender": "Male",
        "SeniorCitizen": 0,
        "Partner": "Yes",
        "Dependents": "No",
        "tenure": 24,
        "PhoneService": "Yes",
        "MultipleLines": "No",
        "InternetService": "Fiber optic",
        "OnlineSecurity": "No",
        "OnlineBackup": "Yes",
        "DeviceProtection": "No",
        "TechSupport": "No",
        "StreamingTV": "No",
        "StreamingMovies": "No",
        "Contract": "Month-to-month",
        "PaperlessBilling": "Yes",
        "PaymentMethod": "Electronic check",
        "MonthlyCharges": 89.5,
        "TotalCharges": 2148.0
    }'

ğŸŒ API en la Nube (Render) 

    La API estÃ¡ desplegada en Render y es accesible desde cualquier navegador: 

    URL: https://churn-prediction-api-1cqs.onrender.com 

    Endpoints 

    GET /health â†’ Verifica estado del modelo.
    POST /predict â†’ Realiza predicciÃ³n de churn.
    GET / â†’ PÃ¡gina web interactiva.
     

    âœ… Esta demostraciÃ³n confirma que el modelo puede ser usado en producciÃ³n real. 
     
ğŸ§  MetodologÃ­a Aplicada 

    Top-Down + Baby Steps: DiseÃ±o incremental desde el main.py hasta la implementaciÃ³n de mÃ³dulos.
    VS Code como IDE principal, con celdas #%% para ejecuciÃ³n interactiva.
    Control de versiones con Git/GitHub, usando ramas main y development.
    Preprocesamiento: One-Hot Encoding, StandardScaler, divisiÃ³n estratificada 70/15/15.
    Modelos: 5 arquitecturas de MLP con variaciÃ³n de hiperparÃ¡metros.
    EvaluaciÃ³n: MÃ©tricas en conjunto de prueba (al menos 5 estadÃ­sticos).
    ComparaciÃ³n con modelo base: RegresiÃ³n LogÃ­stica.
    ValidaciÃ³n cruzada: 5-Fold para evaluar generalizaciÃ³n.
     
ğŸ¤– DeclaraciÃ³n de Uso de LLM 

    Este proyecto fue desarrollado bajo la supervisiÃ³n del estudiante. Se utilizÃ³ una herramienta de inteligencia artificial generativa (LLM) para asistir en la redacciÃ³n del informe, diseÃ±o de la estructura del cÃ³digo, explicaciones tÃ©cnicas y generaciÃ³n de ejemplos. Todas las decisiones de modelado, anÃ¡lisis de resultados, entrenamiento y validaciÃ³n fueron realizadas y verificadas por el autor. La herramienta no generÃ³ resultados directos sin supervisiÃ³n ni ejecutÃ³ cÃ³digo por sÃ­ sola. 
     
ğŸ“š BibliografÃ­a 

    Chollet, F. (2021). Deep Learning with Python (2nd ed.). Manning.
    Goodfellow, I., Bengio, Y., & Courville, A. (2016). Deep Learning. MIT Press.
    Kaggle. (2018). Telco Customer Churn Dataset. https://www.kaggle.com/blastchar/telco-customer-churn 
    Dr. Vladimir GutiÃ©rrez. (2025). Redes Neuronales Artificiales y Aprendizaje Profundo (Cap. 01 - Cap. 08-2).
     