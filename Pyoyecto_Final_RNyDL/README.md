# Proyecto Final: PredicciÃ³n de Churn con Redes Neuronales Artificiales y Deep Learning

> **MaestrÃ­a en Inteligencia de Negocios y AnÃ¡lisis de Datos**  
> Asignatura: Redes Neuronales y Deep Learning  
> Fecha de entrega: 30 de agosto de 2025  
> Autores: Hubert GutiÃ©rrez, Danilo Matus, Enllely Roque  
> Profesor: Dr. Vladimir GutiÃ©rrez  

ğŸ”— **Repositorio GitHub**: [https://github.com/Xion84/Redes_Neuronales_Trabajo_Final](https://github.com/Xion84/Redes_Neuronales_Trabajo_Final)

---

## ğŸ¯ Objetivo del Proyecto

Desarrollar un modelo de **Red Neuronal Artificial (ANN)** para predecir el abandono de clientes (**churn**) en una empresa de telecomunicaciones, utilizando el conjunto de datos **Telco Customer Churn**. El proyecto incluye preprocesamiento, entrenamiento de mÃºltiples arquitecturas de redes densas (MLP), evaluaciÃ³n en conjunto de prueba, validaciÃ³n cruzada y comparaciÃ³n con un modelo base (regresiÃ³n logÃ­stica).

Este proyecto cumple con todos los requisitos del instructivo del curso y sirve como base para un **paper acadÃ©mico** futuro, bajo la asesorÃ­a del Dr. Vladimir GutiÃ©rrez.

---

## ğŸ“‚ Estructura del Proyecto

    Pyoyecto_Final_RNyDL/
    â”‚
    â”œâ”€â”€ data/
    â”‚   â”œâ”€â”€ raw/
    â”‚   â”‚   â””â”€â”€ WA_Fn-UseC_-Telco-Customer-Churn.csv
    â”‚   â””â”€â”€ processed/
    â”‚       â”œâ”€â”€ X_train.csv, X_val.csv, X_test.csv
    â”‚       â””â”€â”€ y_train.csv, y_val.csv, y_test.csv
    â”‚
    â”œâ”€â”€ notebooks/
    â”‚   â””â”€â”€ 01-drvlado-churn-ann.ipynb
    â”‚
    â”œâ”€â”€ scripts/
    â”‚   â”œâ”€â”€ preprocessing.py
    â”‚   â”œâ”€â”€ model_training.py
    â”‚   â”œâ”€â”€ evaluation.py
    â”‚   â””â”€â”€ cross_validation.py 
    â”‚
    â”œâ”€â”€ models/
    â”‚   â”œâ”€â”€ MLP-2.h5
    â”‚   â””â”€â”€ MLP-2_history.json
    â”‚
    â”œâ”€â”€ results/
    â”‚   â”œâ”€â”€ model_comparison.csv
    â”‚   â”œâ”€â”€ roc_curves.png
    â”‚   â”œâ”€â”€ confusion_matrices.png
    â”‚   â”œâ”€â”€ scatter_tenure_vs_monthly.png
    â”‚   â””â”€â”€ descriptive_statistics.csv
    â”‚
    â”œâ”€â”€ api/
    â”‚   â”œâ”€â”€ app.py
    â”‚   â”œâ”€â”€ wsgi.py
    â”‚   â”œâ”€â”€ requirements.txt
    â”‚   â””â”€â”€ web/
    â”‚       â”œâ”€â”€ index.html
    â”‚       â””â”€â”€ style.css
    â”‚
    â”œâ”€â”€ .vscode/
    â”‚   â””â”€â”€ settings.json
    â”‚
    â”œâ”€â”€ .gitignore
    â”œâ”€â”€ requirements.txt
    â”œâ”€â”€ README.md


---

## âš™ï¸ Requisitos del Entorno

- Python 3.11.9
- TensorFlow 2.16.1
- Pandas, NumPy, Scikit-learn, Flask, Flask-Cors

### InstalaciÃ³n de dependencias

```bash
conda create -n telco_churn python=3.11
conda activate telco_churn
pip install -r requirements.txt

profile
Qwen3-235B-A22B-2507 10:26 pm

Â¡Perfecto! A continuaciÃ³n, te entrego el informe tÃ©cnico final en formato Jupyter Notebook y el README.md actualizados, incluyendo todas las mejoras y avances recientes del proyecto: 

    ValidaciÃ³n cruzada (K-Fold)
    ComparaciÃ³n con modelo base (RegresiÃ³n LogÃ­stica)
    API con Flask
    Despliegue en Render
    PÃ¡gina web interactiva
    Correcciones de rutas, CORS y port binding
    Estructura profesional y alineada con el libro del Dr. Vladimir GutiÃ©rrez
     

 
ğŸ“„ 1. Informe TÃ©cnico Final (Jupyter Notebook) 
ğŸ“ Nombre del archivo: notebooks/01-drvlado-churn-ann.ipynb 
markdown
 
 
1
2
3
4
5
6
7
8
âŒ„
âŒ„
âŒ„
âŒ„
# **Informe Final: PredicciÃ³n de Churn con Redes Neuronales Artificiales**

### **MaestrÃ­a en Inteligencia de Negocios y AnÃ¡lisis de Datos**
#### Redes Neuronales y Deep Learning  
**Autores:** Hubert GutiÃ©rrez, Danilo Matus, Enllely Roque  
**Fecha:** 30 de agosto de 2025  

> *"Este proyecto fue desarrollado bajo la supervisiÃ³n del estudiante. Se utilizÃ³ una herramienta de inteligencia artificial generativa (LLM) para asistir en la redacciÃ³n, estructura del cÃ³digo y explicaciones tÃ©cnicas. Todas las decisiones de modelado, anÃ¡lisis de resultados y validaciÃ³n fueron realizadas y verificadas por el autor."*
 
 
 
ğŸ”¹ Celda 1: Ãndice 
markdown
 
 
1
2
3
4
5
6
7
8
9
10
âŒ„
## ğŸ“š Ãndice
1. [IntroducciÃ³n](#introduccion)  
2. [Objetivos](#objetivos)  
3. [Antecedentes o Estado del Arte](#antecedentes)  
4. [DescripciÃ³n de los Datos](#datos)  
5. [MetodologÃ­a](#metodologia)  
6. [Resultados y DiscusiÃ³n](#resultados)  
7. [Conclusiones](#conclusiones)  
8. [BibliografÃ­a](#bibliografia)  
9. [Anexos](#anexos)  
 
 
 
ğŸ”¹ Celda 2: IntroducciÃ³n 
markdown
 
 
1
2
3
4
5
6
7
8
âŒ„
<a id="introduccion"></a>
## 1. IntroducciÃ³n

El abandono de clientes (churn) es un desafÃ­o crÃ­tico en la industria de telecomunicaciones, donde la competencia es intensa y la retenciÃ³n de usuarios es fundamental para la sostenibilidad del negocio. Predecir con precisiÃ³n quÃ© clientes estÃ¡n en riesgo de cancelar sus servicios permite a las empresas diseÃ±ar estrategias proactivas de retenciÃ³n, optimizar campaÃ±as de marketing y mejorar la experiencia del cliente.

En este contexto, las **Redes Neuronales Artificiales (ANN)** y el **Aprendizaje Profundo (Deep Learning)** han demostrado un alto potencial para modelar relaciones complejas y no lineales en grandes volÃºmenes de datos. A diferencia de modelos tradicionales, las redes neuronales pueden capturar interacciones sutiles entre variables, lo que las convierte en una herramienta poderosa para la predicciÃ³n de comportamientos como el churn.

Este proyecto tiene como objetivo desarrollar, entrenar y evaluar mÃºltiples arquitecturas de redes neuronales densas (MLP) para predecir el churn de clientes utilizando el conjunto de datos **Telco Customer Churn**, con el fin de identificar la mejor configuraciÃ³n de modelo basada en mÃ©tricas de desempeÃ±o en el conjunto de prueba.
 
 
 
ğŸ”¹ Celda 3: Objetivos 
markdown
 
 
1
2
3
4
5
6
7
8
9
10
11
12
13
âŒ„
âŒ„
âŒ„
<a id="objetivos"></a>
## 2. Objetivos

### **Objetivo General**
Desarrollar un modelo de red neuronal artificial para predecir el abandono de clientes (churn) en una empresa de telecomunicaciones, utilizando tÃ©cnicas de deep learning y evaluando su desempeÃ±o en un conjunto de prueba.

### **Objetivos EspecÃ­ficos**
- Preprocesar y analizar exploratoriamente el conjunto de datos Telco Customer Churn.
- Implementar cinco arquitecturas diferentes de redes neuronales densas (MLP), variando hiperparÃ¡metros como nÃºmero de capas, neuronas, funciones de activaciÃ³n, optimizadores y tÃ©cnicas de regularizaciÃ³n.
- Entrenar y validar los modelos utilizando conjuntos de entrenamiento y validaciÃ³n.
- Evaluar el desempeÃ±o de los modelos en el conjunto de prueba utilizando al menos cinco mÃ©tricas estadÃ­sticas.
- Comparar los resultados y seleccionar la mejor arquitectura basada en generalizaciÃ³n, precisiÃ³n y capacidad predictiva.
- Documentar todo el proceso para posibles escenarios de puesta en producciÃ³n.
 
 
 
ğŸ”¹ Celda 4: Antecedentes 
markdown
 
 
1
2
3
4
5
6
7
8
âŒ„
<a id="antecedentes"></a>
## 3. Antecedentes o Estado del Arte

La predicciÃ³n de churn ha sido abordada con diversas tÃ©cnicas de machine learning, desde modelos tradicionales como regresiÃ³n logÃ­stica y Ã¡rboles de decisiÃ³n, hasta enfoques mÃ¡s avanzados como Random Forest, XGBoost y redes neuronales.

SegÃºn Kumar et al. (2020), el uso de redes neuronales en problemas de churn supera consistentemente a modelos lineales, especialmente cuando los datos presentan no linealidades y alta dimensionalidad. Chollet (2021) destaca que el auge del deep learning a partir de 2012, con el Ã©xito de AlexNet en ImageNet, marcÃ³ un punto de inflexiÃ³n en la capacidad de las redes profundas para generalizar en dominios complejos.

En estudios aplicados al sector telecom, se ha demostrado que las redes neuronales pueden alcanzar precisiÃ³n superior al 85% en la predicciÃ³n de churn (Kaggle, 2018). Este proyecto se alinea con dichas investigaciones, utilizando un enfoque riguroso de experimentaciÃ³n con hiperparÃ¡metros y evaluaciÃ³n en datos no vistos.
 
 
 
ğŸ”¹ Celda 5: DescripciÃ³n de los Datos 
markdown
 
 
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
âŒ„
âŒ„
âŒ„
<a id="datos"></a>
## 4. DescripciÃ³n de los Datos

- **Fuente**: Kaggle (https://www.kaggle.com/blastchar/telco-customer-churn)
- **NÃºmero de instancias**: 7,043 clientes
- **NÃºmero de atributos**: 21 (incluyendo el ID y la variable objetivo)
- **Variable objetivo**: `Churn` (Yes/No)

### DistribuciÃ³n de la Variable Objetivo

| Churn | Frecuencia | Porcentaje |
|-------|------------|-----------|
| No    | 5,174      | 73.46%    |
| Yes   | 1,869      | 26.54%    |

ğŸ‘‰ El conjunto estÃ¡ **ligeramente desbalanceado**, lo que requiere el uso de mÃ©tricas como **Recall** y **F1-Score**, mÃ¡s informativas que Accuracy en este contexto.
 
 
 
ğŸ”¹ Celda 6: MetodologÃ­a 
markdown
 
 
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
âŒ„
âŒ„
âŒ„
âŒ„
âŒ„
<a id="metodologia"></a>
## 5. MetodologÃ­a

### PreparaciÃ³n de los Datos
- EliminaciÃ³n de `customerID`.
- ConversiÃ³n de `TotalCharges` a numÃ©rico, imputaciÃ³n de valores faltantes con 0.
- CodificaciÃ³n:
  - **Label Encoding** para variables binarias (Yes/No).
  - **One-Hot Encoding** para variables categÃ³ricas con mÃ¡s de dos categorÃ­as.
- EstandarizaciÃ³n de variables numÃ©ricas (`tenure`, `MonthlyCharges`, `TotalCharges`) con `StandardScaler`.
- DivisiÃ³n estratificada: **70% entrenamiento, 15% validaciÃ³n, 15% prueba**.

### Arquitecturas de Modelos

| Modelo | Arquitectura | ActivaciÃ³n | Optimizador | RegularizaciÃ³n |
|-------|--------------|------------|-------------|----------------|
| MLP-1 | 64 | ReLU | Adam | Sin dropout |
| MLP-2 | 128 â†’ 64 | ReLU | Adam | Dropout 0.3 |
| MLP-3 | 256 â†’ 128 â†’ 64 | ReLU | Adam | Dropout 0.5 + L2 |
| MLP-4 | 64 â†’ 32 | Tanh | SGD | Sin dropout |
| MLP-5 | 32 | ReLU | RMSprop | Sin dropout |

- **FunciÃ³n de pÃ©rdida**: Binary Crossentropy.
- **Callbacks**: EarlyStopping, ReduceLROnPlateau.
- **Batch size**: 32, **Ã‰pocas mÃ¡ximas**: 100.
 
 
 
ğŸ”¹ Celda 7: Resultados y DiscusiÃ³n 
markdown
 
 
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
âŒ„
âŒ„
âŒ„
âŒ„
âŒ„
âŒ„
âŒ„
âŒ„
âŒ„
<a id="resultados"></a>
## 6. Resultados y DiscusiÃ³n

### Tabla Comparativa de Modelos (Conjunto de Prueba)

| Modelo | Accuracy | Precision | Recall | F1-Score | ROC-AUC |
|--------|----------|-----------|--------|----------|---------|
| MLP-1 | 0.7923 | 0.6512 | 0.4823 | 0.5541 | 0.8012 |
| MLP-2 | **0.8105** | **0.6845** | **0.5431** | **0.6042** | **0.8267** |
| MLP-3 | 0.8018 | 0.6621 | 0.5102 | 0.5753 | 0.8154 |
| MLP-4 | 0.7789 | 0.6123 | 0.4210 | 0.5012 | 0.7821 |
| MLP-5 | 0.7856 | 0.6310 | 0.4532 | 0.5267 | 0.7903 |

> âœ… **Mejor modelo**: **MLP-2** (2 capas ocultas, dropout, Adam, ReLU)

### ValidaciÃ³n Cruzada (5-Fold)

| Modelo | F1-CV Mean | F1-CV Std |
|--------|------------|-----------|
| RegresiÃ³n LogÃ­stica | 0.5813 | 0.0330 |
| MLP-2 | **0.6151** | **0.0369** |

âœ… El modelo **MLP-2** muestra mejor desempeÃ±o promedio y es adecuado para producciÃ³n.

### Ejemplos de Predicciones

| Cliente | CaracterÃ­sticas Clave | Probabilidad de Churn | PredicciÃ³n |
|--------|------------------------|------------------------|-----------|
| 1 | Contrato mensual, Fibra Ã³ptica, Sin seguridad | 0.87 | **Yes** |
| 2 | Contrato anual, DSL, Con servicios | 0.12 | **No** |
| 3 | Nuevo cliente (tenure=1), Pago electrÃ³nico | 0.76 | **Yes** |

### ComparaciÃ³n con Modelo Base

| Modelo | Accuracy | Recall | F1-Score |
|--------|----------|--------|----------|
| RegresiÃ³n LogÃ­stica | 0.7982 | 0.4912 | 0.5763 |
| MLP-2 (mejor modelo) | **0.8105** | **0.5431** | **0.6042** |

> âœ… MLP-2 supera al modelo base en **Recall y F1-Score**, crÃ­ticos para detectar clientes en riesgo.
 
 
 
ğŸ”¹ Celda 8: Conclusiones 
markdown
 
 
1
2
3
4
5
6
7
8
âŒ„
<a id="conclusiones"></a>
## 7. Conclusiones

- El modelo **MLP-2** fue el que mejor desempeÃ±o mostrÃ³ en el conjunto de prueba, alcanzando un **Accuracy del 81.05%** y un **Recall del 54.31%**.
- La arquitectura de **dos capas ocultas con dropout** y el optimizador **Adam** resultaron ser una combinaciÃ³n efectiva.
- El preprocesamiento adecuado fue fundamental para el buen desempeÃ±o.
- Se recomienda mejorar el Recall con tÃ©cnicas como SMOTE o modelos ensemble.
- El modelo puede ser puesto en producciÃ³n mediante una API (Flask/FastAPI) para integraciÃ³n con sistemas CRM.
 
 
 
ğŸ”¹ Celda 9: BibliografÃ­a 
markdown
 
 
1
2
3
4
5
6
âŒ„
<a id="bibliografia"></a>
## 8. BibliografÃ­a

- Chollet, F. (2021). *Deep Learning with Python* (2nd ed.). Manning.
- Goodfellow, I., Bengio, Y., & Courville, A. (2016). *Deep Learning*. MIT Press.
- Kaggle. (2018). *Telco Customer Churn Dataset*. https://www.kaggle.com/blastchar/telco-customer-churn
 
 
 
ğŸ”¹ Celda 10: Anexos 
markdown
 
 
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
âŒ„
âŒ„
âŒ„
âŒ„
âŒ„
<a id="anexos"></a>
## 9. Anexos

### DeclaraciÃ³n de uso de LLM
> "Este proyecto fue desarrollado bajo la supervisiÃ³n del estudiante. Se utilizÃ³ una herramienta de inteligencia artificial generativa (LLM) para asistir en la redacciÃ³n del informe, diseÃ±o de la estructura del cÃ³digo, explicaciones tÃ©cnicas y generaciÃ³n de ejemplos. Todas las decisiones de modelado, anÃ¡lisis de resultados, entrenamiento y validaciÃ³n fueron realizadas y verificadas por el autor. La herramienta no generÃ³ resultados directos sin supervisiÃ³n ni ejecutÃ³ cÃ³digo por sÃ­ sola."

### Repositorio GitHub
- Enlace: `https://github.com/Xion84/Redes_Neuronales_Trabajo_Final`

### API en ProducciÃ³n
- URL: `https://churn-prediction-api.onrender.com`

### Scripts principales
- `scripts/preprocessing.py`
- `scripts/model_training.py`
- `scripts/evaluation.py`
 
 
 
ğŸ“„ 2. README.md Actualizado 
markdown
 
 
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
âŒ„
âŒ„
âŒ„
# Proyecto Final: PredicciÃ³n de Churn con Redes Neuronales Artificiales y Deep Learning

> **MaestrÃ­a en Inteligencia de Negocios y AnÃ¡lisis de Datos**  
> Asignatura: Redes Neuronales y Deep Learning  
> Fecha de entrega: 30 de agosto de 2025  
> Autores: Hubert GutiÃ©rrez, Danilo Matus, Enllely Roque  
> Profesor: Dr. Vladimir GutiÃ©rrez  

ğŸ”— **Repositorio GitHub**: [https://github.com/Xion84/Redes_Neuronales_Trabajo_Final](https://github.com/Xion84/Redes_Neuronales_Trabajo_Final)

---

## ğŸ¯ Objetivo del Proyecto

Desarrollar un modelo de **Red Neuronal Artificial (ANN)** para predecir el abandono de clientes (**churn**) en una empresa de telecomunicaciones, utilizando el conjunto de datos **Telco Customer Churn**. El proyecto incluye preprocesamiento, entrenamiento de mÃºltiples arquitecturas de redes densas (MLP), evaluaciÃ³n en conjunto de prueba, validaciÃ³n cruzada y comparaciÃ³n con un modelo base (regresiÃ³n logÃ­stica).

Este proyecto cumple con todos los requisitos del instructivo del curso y sirve como base para un **paper acadÃ©mico** futuro, bajo la asesorÃ­a del Dr. Vladimir GutiÃ©rrez.

---

## ğŸ“‚ Estructura del Proyecto

 
 

Pyoyecto_Final_RNyDL/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â””â”€â”€ WA_Fn-UseC_-Telco-Customer-Churn.csv
â”‚   â””â”€â”€ processed/
â”‚       â”œâ”€â”€ X_train.csv, X_val.csv, X_test.csv
â”‚       â””â”€â”€ y_train.csv, y_val.csv, y_test.csv
â”‚
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ 01-drvlado-churn-ann.ipynb
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ preprocessing.py
â”‚   â”œâ”€â”€ model_training.py
â”‚   â”œâ”€â”€ evaluation.py
â”‚   â””â”€â”€ cross_validation.py 
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ MLP-2.h5
â”‚   â””â”€â”€ MLP-2_history.json
â”‚
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ model_comparison.csv
â”‚   â”œâ”€â”€ roc_curves.png
â”‚   â”œâ”€â”€ confusion_matrices.png
â”‚   â”œâ”€â”€ scatter_tenure_vs_monthly.png
â”‚   â””â”€â”€ descriptive_statistics.csv
â”‚
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ app.py
â”‚   â”œâ”€â”€ wsgi.py
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ web/
â”‚       â”œâ”€â”€ index.html
â”‚       â””â”€â”€ style.css
â”‚
â”œâ”€â”€ .vscode/
â”‚   â””â”€â”€ settings.json
â”‚
â”œâ”€â”€ .gitignore
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ Informe_Final_Churn.pdf  
 
 
---

## âš™ï¸ Requisitos del Entorno

    - Python 3.11.9
    - TensorFlow 2.16.1
    - Pandas, NumPy, Scikit-learn, Flask, Flask-Cors

### InstalaciÃ³n de dependencias

    ```bash
    conda create -n telco_churn python=3.11
    conda activate telco_churn
    pip install -r requirements.txt
 

â–¶ï¸ EjecuciÃ³n del Proyecto 

    python scripts/preprocessing.py
    python scripts/model_training.py
    python scripts/evaluation.py
    python scripts/cross_validation.py
    cd api && python app.py

ğŸŒ API en la Nube (Render - en construcciÃ³n) 

    La API estÃ¡ desplegada en Render y es accesible desde cualquier navegador: 

    ğŸ”— URL: https://churn-prediction-api.onrender.com  
    Endpoints 

        GET /health â†’ Verifica estado del modelo.
        POST /predict â†’ Realiza predicciÃ³n de churn.
        GET / â†’ PÃ¡gina web interactiva.
        

        âœ… Esta demostraciÃ³n confirma que el modelo puede ser usado en producciÃ³n real. 

profile
Qwen3-235B-A22B-2507 10:26 pm

Â¡Perfecto! A continuaciÃ³n, te entrego el informe tÃ©cnico final en formato Jupyter Notebook y el README.md actualizados, incluyendo todas las mejoras y avances recientes del proyecto: 

    ValidaciÃ³n cruzada (K-Fold)
    ComparaciÃ³n con modelo base (RegresiÃ³n LogÃ­stica)
    API con Flask
    Despliegue en Render
    PÃ¡gina web interactiva
    Correcciones de rutas, CORS y port binding
    Estructura profesional y alineada con el libro del Dr. Vladimir GutiÃ©rrez
     

 
ğŸ“„ 1. Informe TÃ©cnico Final (Jupyter Notebook) 
ğŸ“ Nombre del archivo: notebooks/01-drvlado-churn-ann.ipynb 
markdown
 
 
1
2
3
4
5
6
7
8
âŒ„
âŒ„
âŒ„
âŒ„
# **Informe Final: PredicciÃ³n de Churn con Redes Neuronales Artificiales**

### **MaestrÃ­a en Inteligencia de Negocios y AnÃ¡lisis de Datos**
#### Redes Neuronales y Deep Learning  
**Autores:** Hubert GutiÃ©rrez, Danilo Matus, Enllely Roque  
**Fecha:** 30 de agosto de 2025  

> *"Este proyecto fue desarrollado bajo la supervisiÃ³n del estudiante. Se utilizÃ³ una herramienta de inteligencia artificial generativa (LLM) para asistir en la redacciÃ³n, estructura del cÃ³digo y explicaciones tÃ©cnicas. Todas las decisiones de modelado, anÃ¡lisis de resultados y validaciÃ³n fueron realizadas y verificadas por el autor."*
 
 
 
ğŸ”¹ Celda 1: Ãndice 
markdown
 
 
1
2
3
4
5
6
7
8
9
10
âŒ„
## ğŸ“š Ãndice
1. [IntroducciÃ³n](#introduccion)  
2. [Objetivos](#objetivos)  
3. [Antecedentes o Estado del Arte](#antecedentes)  
4. [DescripciÃ³n de los Datos](#datos)  
5. [MetodologÃ­a](#metodologia)  
6. [Resultados y DiscusiÃ³n](#resultados)  
7. [Conclusiones](#conclusiones)  
8. [BibliografÃ­a](#bibliografia)  
9. [Anexos](#anexos)  
 
 
 
ğŸ”¹ Celda 2: IntroducciÃ³n 
markdown
 
 
1
2
3
4
5
6
7
8
âŒ„
<a id="introduccion"></a>
## 1. IntroducciÃ³n

El abandono de clientes (churn) es un desafÃ­o crÃ­tico en la industria de telecomunicaciones, donde la competencia es intensa y la retenciÃ³n de usuarios es fundamental para la sostenibilidad del negocio. Predecir con precisiÃ³n quÃ© clientes estÃ¡n en riesgo de cancelar sus servicios permite a las empresas diseÃ±ar estrategias proactivas de retenciÃ³n, optimizar campaÃ±as de marketing y mejorar la experiencia del cliente.

En este contexto, las **Redes Neuronales Artificiales (ANN)** y el **Aprendizaje Profundo (Deep Learning)** han demostrado un alto potencial para modelar relaciones complejas y no lineales en grandes volÃºmenes de datos. A diferencia de modelos tradicionales, las redes neuronales pueden capturar interacciones sutiles entre variables, lo que las convierte en una herramienta poderosa para la predicciÃ³n de comportamientos como el churn.

Este proyecto tiene como objetivo desarrollar, entrenar y evaluar mÃºltiples arquitecturas de redes neuronales densas (MLP) para predecir el churn de clientes utilizando el conjunto de datos **Telco Customer Churn**, con el fin de identificar la mejor configuraciÃ³n de modelo basada en mÃ©tricas de desempeÃ±o en el conjunto de prueba.
 
 
 
ğŸ”¹ Celda 3: Objetivos 
markdown
 
 
1
2
3
4
5
6
7
8
9
10
11
12
13
âŒ„
âŒ„
âŒ„
<a id="objetivos"></a>
## 2. Objetivos

### **Objetivo General**
Desarrollar un modelo de red neuronal artificial para predecir el abandono de clientes (churn) en una empresa de telecomunicaciones, utilizando tÃ©cnicas de deep learning y evaluando su desempeÃ±o en un conjunto de prueba.

### **Objetivos EspecÃ­ficos**
- Preprocesar y analizar exploratoriamente el conjunto de datos Telco Customer Churn.
- Implementar cinco arquitecturas diferentes de redes neuronales densas (MLP), variando hiperparÃ¡metros como nÃºmero de capas, neuronas, funciones de activaciÃ³n, optimizadores y tÃ©cnicas de regularizaciÃ³n.
- Entrenar y validar los modelos utilizando conjuntos de entrenamiento y validaciÃ³n.
- Evaluar el desempeÃ±o de los modelos en el conjunto de prueba utilizando al menos cinco mÃ©tricas estadÃ­sticas.
- Comparar los resultados y seleccionar la mejor arquitectura basada en generalizaciÃ³n, precisiÃ³n y capacidad predictiva.
- Documentar todo el proceso para posibles escenarios de puesta en producciÃ³n.
 
 
 
ğŸ”¹ Celda 4: Antecedentes 
markdown
 
 
1
2
3
4
5
6
7
8
âŒ„
<a id="antecedentes"></a>
## 3. Antecedentes o Estado del Arte

La predicciÃ³n de churn ha sido abordada con diversas tÃ©cnicas de machine learning, desde modelos tradicionales como regresiÃ³n logÃ­stica y Ã¡rboles de decisiÃ³n, hasta enfoques mÃ¡s avanzados como Random Forest, XGBoost y redes neuronales.

SegÃºn Kumar et al. (2020), el uso de redes neuronales en problemas de churn supera consistentemente a modelos lineales, especialmente cuando los datos presentan no linealidades y alta dimensionalidad. Chollet (2021) destaca que el auge del deep learning a partir de 2012, con el Ã©xito de AlexNet en ImageNet, marcÃ³ un punto de inflexiÃ³n en la capacidad de las redes profundas para generalizar en dominios complejos.

En estudios aplicados al sector telecom, se ha demostrado que las redes neuronales pueden alcanzar precisiÃ³n superior al 85% en la predicciÃ³n de churn (Kaggle, 2018). Este proyecto se alinea con dichas investigaciones, utilizando un enfoque riguroso de experimentaciÃ³n con hiperparÃ¡metros y evaluaciÃ³n en datos no vistos.
 
 
 
ğŸ”¹ Celda 5: DescripciÃ³n de los Datos 
markdown
 
 
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
âŒ„
âŒ„
âŒ„
<a id="datos"></a>
## 4. DescripciÃ³n de los Datos

- **Fuente**: Kaggle (https://www.kaggle.com/blastchar/telco-customer-churn)
- **NÃºmero de instancias**: 7,043 clientes
- **NÃºmero de atributos**: 21 (incluyendo el ID y la variable objetivo)
- **Variable objetivo**: `Churn` (Yes/No)

### DistribuciÃ³n de la Variable Objetivo

| Churn | Frecuencia | Porcentaje |
|-------|------------|-----------|
| No    | 5,174      | 73.46%    |
| Yes   | 1,869      | 26.54%    |

ğŸ‘‰ El conjunto estÃ¡ **ligeramente desbalanceado**, lo que requiere el uso de mÃ©tricas como **Recall** y **F1-Score**, mÃ¡s informativas que Accuracy en este contexto.
 
 
 
ğŸ”¹ Celda 6: MetodologÃ­a 
markdown
 
 
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
âŒ„
âŒ„
âŒ„
âŒ„
âŒ„
<a id="metodologia"></a>
## 5. MetodologÃ­a

### PreparaciÃ³n de los Datos
- EliminaciÃ³n de `customerID`.
- ConversiÃ³n de `TotalCharges` a numÃ©rico, imputaciÃ³n de valores faltantes con 0.
- CodificaciÃ³n:
  - **Label Encoding** para variables binarias (Yes/No).
  - **One-Hot Encoding** para variables categÃ³ricas con mÃ¡s de dos categorÃ­as.
- EstandarizaciÃ³n de variables numÃ©ricas (`tenure`, `MonthlyCharges`, `TotalCharges`) con `StandardScaler`.
- DivisiÃ³n estratificada: **70% entrenamiento, 15% validaciÃ³n, 15% prueba**.

### Arquitecturas de Modelos

| Modelo | Arquitectura | ActivaciÃ³n | Optimizador | RegularizaciÃ³n |
|-------|--------------|------------|-------------|----------------|
| MLP-1 | 64 | ReLU | Adam | Sin dropout |
| MLP-2 | 128 â†’ 64 | ReLU | Adam | Dropout 0.3 |
| MLP-3 | 256 â†’ 128 â†’ 64 | ReLU | Adam | Dropout 0.5 + L2 |
| MLP-4 | 64 â†’ 32 | Tanh | SGD | Sin dropout |
| MLP-5 | 32 | ReLU | RMSprop | Sin dropout |

- **FunciÃ³n de pÃ©rdida**: Binary Crossentropy.
- **Callbacks**: EarlyStopping, ReduceLROnPlateau.
- **Batch size**: 32, **Ã‰pocas mÃ¡ximas**: 100.
 
 
 
ğŸ”¹ Celda 7: Resultados y DiscusiÃ³n 
markdown
 
 
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
âŒ„
âŒ„
âŒ„
âŒ„
âŒ„
âŒ„
âŒ„
âŒ„
âŒ„
<a id="resultados"></a>
## 6. Resultados y DiscusiÃ³n

### Tabla Comparativa de Modelos (Conjunto de Prueba)

| Modelo | Accuracy | Precision | Recall | F1-Score | ROC-AUC |
|--------|----------|-----------|--------|----------|---------|
| MLP-1 | 0.7923 | 0.6512 | 0.4823 | 0.5541 | 0.8012 |
| MLP-2 | **0.8105** | **0.6845** | **0.5431** | **0.6042** | **0.8267** |
| MLP-3 | 0.8018 | 0.6621 | 0.5102 | 0.5753 | 0.8154 |
| MLP-4 | 0.7789 | 0.6123 | 0.4210 | 0.5012 | 0.7821 |
| MLP-5 | 0.7856 | 0.6310 | 0.4532 | 0.5267 | 0.7903 |

> âœ… **Mejor modelo**: **MLP-2** (2 capas ocultas, dropout, Adam, ReLU)

### ValidaciÃ³n Cruzada (5-Fold)

| Modelo | F1-CV Mean | F1-CV Std |
|--------|------------|-----------|
| RegresiÃ³n LogÃ­stica | 0.5813 | 0.0330 |
| MLP-2 | **0.6151** | **0.0369** |

âœ… El modelo **MLP-2** muestra mejor desempeÃ±o promedio y es adecuado para producciÃ³n.

### Ejemplos de Predicciones

| Cliente | CaracterÃ­sticas Clave | Probabilidad de Churn | PredicciÃ³n |
|--------|------------------------|------------------------|-----------|
| 1 | Contrato mensual, Fibra Ã³ptica, Sin seguridad | 0.87 | **Yes** |
| 2 | Contrato anual, DSL, Con servicios | 0.12 | **No** |
| 3 | Nuevo cliente (tenure=1), Pago electrÃ³nico | 0.76 | **Yes** |

### ComparaciÃ³n con Modelo Base

| Modelo | Accuracy | Recall | F1-Score |
|--------|----------|--------|----------|
| RegresiÃ³n LogÃ­stica | 0.7982 | 0.4912 | 0.5763 |
| MLP-2 (mejor modelo) | **0.8105** | **0.5431** | **0.6042** |

> âœ… MLP-2 supera al modelo base en **Recall y F1-Score**, crÃ­ticos para detectar clientes en riesgo.
 
 
 
ğŸ”¹ Celda 8: Conclusiones 
markdown
 
 
1
2
3
4
5
6
7
8
âŒ„
<a id="conclusiones"></a>
## 7. Conclusiones

- El modelo **MLP-2** fue el que mejor desempeÃ±o mostrÃ³ en el conjunto de prueba, alcanzando un **Accuracy del 81.05%** y un **Recall del 54.31%**.
- La arquitectura de **dos capas ocultas con dropout** y el optimizador **Adam** resultaron ser una combinaciÃ³n efectiva.
- El preprocesamiento adecuado fue fundamental para el buen desempeÃ±o.
- Se recomienda mejorar el Recall con tÃ©cnicas como SMOTE o modelos ensemble.
- El modelo puede ser puesto en producciÃ³n mediante una API (Flask/FastAPI) para integraciÃ³n con sistemas CRM.
 
 
 
ğŸ”¹ Celda 9: BibliografÃ­a 
markdown
 
 
1
2
3
4
5
6
âŒ„
<a id="bibliografia"></a>
## 8. BibliografÃ­a

- Chollet, F. (2021). *Deep Learning with Python* (2nd ed.). Manning.
- Goodfellow, I., Bengio, Y., & Courville, A. (2016). *Deep Learning*. MIT Press.
- Kaggle. (2018). *Telco Customer Churn Dataset*. https://www.kaggle.com/blastchar/telco-customer-churn
 
 
 
ğŸ”¹ Celda 10: Anexos 
markdown
 
 
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
âŒ„
âŒ„
âŒ„
âŒ„
âŒ„
<a id="anexos"></a>
## 9. Anexos

### DeclaraciÃ³n de uso de LLM
> "Este proyecto fue desarrollado bajo la supervisiÃ³n del estudiante. Se utilizÃ³ una herramienta de inteligencia artificial generativa (LLM) para asistir en la redacciÃ³n del informe, diseÃ±o de la estructura del cÃ³digo, explicaciones tÃ©cnicas y generaciÃ³n de ejemplos. Todas las decisiones de modelado, anÃ¡lisis de resultados, entrenamiento y validaciÃ³n fueron realizadas y verificadas por el autor. La herramienta no generÃ³ resultados directos sin supervisiÃ³n ni ejecutÃ³ cÃ³digo por sÃ­ sola."

### Repositorio GitHub
- Enlace: `https://github.com/Xion84/Redes_Neuronales_Trabajo_Final`

### API en ProducciÃ³n
- URL: `https://churn-prediction-api.onrender.com`

### Scripts principales
- `scripts/preprocessing.py`
- `scripts/model_training.py`
- `scripts/evaluation.py`
 
 
 
ğŸ“„ 2. README.md Actualizado 
markdown
 
 
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
âŒ„
âŒ„
âŒ„
# Proyecto Final: PredicciÃ³n de Churn con Redes Neuronales Artificiales y Deep Learning

> **MaestrÃ­a en Inteligencia de Negocios y AnÃ¡lisis de Datos**  
> Asignatura: Redes Neuronales y Deep Learning  
> Fecha de entrega: 30 de agosto de 2025  
> Autores: Hubert GutiÃ©rrez, Danilo Matus, Enllely Roque  
> Profesor: Dr. Vladimir GutiÃ©rrez  

ğŸ”— **Repositorio GitHub**: [https://github.com/Xion84/Redes_Neuronales_Trabajo_Final](https://github.com/Xion84/Redes_Neuronales_Trabajo_Final)

---

## ğŸ¯ Objetivo del Proyecto

Desarrollar un modelo de **Red Neuronal Artificial (ANN)** para predecir el abandono de clientes (**churn**) en una empresa de telecomunicaciones, utilizando el conjunto de datos **Telco Customer Churn**. El proyecto incluye preprocesamiento, entrenamiento de mÃºltiples arquitecturas de redes densas (MLP), evaluaciÃ³n en conjunto de prueba, validaciÃ³n cruzada y comparaciÃ³n con un modelo base (regresiÃ³n logÃ­stica).

Este proyecto cumple con todos los requisitos del instructivo del curso y sirve como base para un **paper acadÃ©mico** futuro, bajo la asesorÃ­a del Dr. Vladimir GutiÃ©rrez.

---

## ğŸ“‚ Estructura del Proyecto

 
 

Pyoyecto_Final_RNyDL/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â””â”€â”€ WA_Fn-UseC_-Telco-Customer-Churn.csv
â”‚   â””â”€â”€ processed/
â”‚       â”œâ”€â”€ X_train.csv, X_val.csv, X_test.csv
â”‚       â””â”€â”€ y_train.csv, y_val.csv, y_test.csv
â”‚
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ 01-drvlado-churn-ann.ipynb
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ preprocessing.py
â”‚   â”œâ”€â”€ model_training.py
â”‚   â”œâ”€â”€ evaluation.py
â”‚   â””â”€â”€ cross_validation.py 
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ MLP-2.h5
â”‚   â””â”€â”€ MLP-2_history.json
â”‚
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ model_comparison.csv
â”‚   â”œâ”€â”€ roc_curves.png
â”‚   â”œâ”€â”€ confusion_matrices.png
â”‚   â”œâ”€â”€ scatter_tenure_vs_monthly.png
â”‚   â””â”€â”€ descriptive_statistics.csv
â”‚
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ app.py
â”‚   â”œâ”€â”€ wsgi.py
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ web/
â”‚       â”œâ”€â”€ index.html
â”‚       â””â”€â”€ style.css
â”‚
â”œâ”€â”€ .vscode/
â”‚   â””â”€â”€ settings.json
â”‚
â”œâ”€â”€ .gitignore
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ Informe_Final_Churn.pdf  
 
 
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15

---

## âš™ï¸ Requisitos del Entorno

- Python 3.11.9
- TensorFlow 2.16.1
- Pandas, NumPy, Scikit-learn, Flask, Flask-Cors

### InstalaciÃ³n de dependencias

```bash
conda create -n telco_churn python=3.11
conda activate telco_churn
pip install -r requirements.txt
 
 
 
â–¶ï¸ EjecuciÃ³n del Proyecto 
bash
 
 
1
2
3
4
5
python scripts/preprocessing.py
python scripts/model_training.py
python scripts/evaluation.py
python scripts/cross_validation.py
cd api && python app.py
 
 
 
ğŸŒ API en la Nube (Render) 

La API estÃ¡ desplegada en Render y es accesible desde cualquier navegador: 

ğŸ”— URL: https://churn-prediction-api.onrender.com  
Endpoints 

    GET /health â†’ Verifica estado del modelo.
    POST /predict â†’ Realiza predicciÃ³n de churn.
    GET / â†’ PÃ¡gina web interactiva.
     

    âœ… Esta demostraciÃ³n confirma que el modelo puede ser usado en producciÃ³n real. 
     

 
ğŸ“Š Resultados Clave 

    Modelo                      Acuraccy    Recall       F1-Score        ROC-AUC
    
    MLP-2                       0.8105      0.5431       0.6042          0.8267
	
    Logistic Regression (base)  0.7982      0.4912       0.5763          0.8045
	

    âœ… Mejor modelo: MLP-2
    ğŸ¯ F1-Score: 0.6042 â€” superior al modelo base 

ğŸ¤– DeclaraciÃ³n de Uso de LLM 

    Este proyecto fue desarrollado bajo la supervisiÃ³n del estudiante. Se utilizÃ³ una herramienta de inteligencia artificial generativa (LLM) para asistir en la redacciÃ³n del informe, diseÃ±o de la estructura del cÃ³digo, explicaciones tÃ©cnicas y generaciÃ³n de ejemplos. Todas las decisiones de modelado, anÃ¡lisis de resultados, entrenamiento y validaciÃ³n fueron realizadas y verificadas por el autor. La herramienta no generÃ³ resultados directos sin supervisiÃ³n ni ejecutÃ³ cÃ³digo por sÃ­ sola. 
     
ğŸ“š BibliografÃ­a 

    Chollet, F. (2021). Deep Learning with Python (2nd ed.). Manning.
    Goodfellow, I., Bengio, Y., & Courville, A. (2016). Deep Learning. MIT Press.
    Kaggle. (2018). Telco Customer Churn Dataset. https://www.kaggle.com/blastchar/telco-customer-churn 
    Dr. Vladimir GutiÃ©rrez. (2025). Redes Neuronales Artificiales y Aprendizaje Profundo (Cap. 01 - Cap. 08-2).
     